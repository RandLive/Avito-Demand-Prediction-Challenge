{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "loading data done!\n",
      "merging supplimentary data done!\n",
      "feature engineering -> fill na ...\n",
      "feature engineering -> hash text ...\n",
      "feature engineering -> preprocess text ...\n",
      "feature engineering -> lable encoding ...\n",
      "feature engineering -> do count ...\n",
      "feature engineering -> date time ...\n",
      "feature engineering -> statistics in text ...\n",
      "feature engineering -> on price and SEQ ...\n",
      "feature engineering -> on price and SEQ ...\n",
      "feature engineering -> on price deal prob +...\n",
      "ridge 1 oof ...\n",
      "Ridege oof Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.5373698818222636e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.5388835960858735e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.53944589567156e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.540236213420533e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.5373584501981726e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.537541358556411e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.5394332178481834e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.539149907245812e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.5393613637581946e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridege oof Fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 4.538533281181959e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 2 oof ...\n",
      "Ridege oof Fold 0\n",
      "Ridege oof Fold 1\n",
      "Ridege oof Fold 2\n",
      "Ridege oof Fold 3\n",
      "Ridege oof Fold 4\n",
      "Ridege oof Fold 5\n",
      "Ridege oof Fold 6\n",
      "Ridege oof Fold 7\n",
      "Ridege oof Fold 8\n",
      "Ridege oof Fold 9\n",
      "Modeling Stage ...\n",
      "1503424 Rows and 1393781 Cols\n",
      "508438 Rows and 1393781 Cols\n",
      "Feature Names Length:  1393781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/qifeng/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttrain's rmse: 0.21765\tvalid's rmse: 0.222344\n",
      "[200]\ttrain's rmse: 0.209952\tvalid's rmse: 0.219187\n",
      "[300]\ttrain's rmse: 0.205262\tvalid's rmse: 0.218309\n",
      "[400]\ttrain's rmse: 0.201575\tvalid's rmse: 0.217811\n",
      "[500]\ttrain's rmse: 0.198607\tvalid's rmse: 0.217538\n"
     ]
    }
   ],
   "source": [
    "# %load LGB_Mengfei_multi_ridge_LB_0.2217.py\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import gc, re\n",
    "from sklearn.utils import shuffle\n",
    "from contextlib import contextmanager\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "debug = False\n",
    "print(\"loading data ...\")\n",
    "used_cols = [\"item_id\", \"user_id\"]\n",
    "if debug == False:\n",
    "    train_df = pd.read_csv('input/train.csv', parse_dates = ['activation_date'])\n",
    "    y = train_df[\"deal_probability\"]\n",
    "    test_df = pd.read_csv('input/test.csv', parse_dates = ['activation_date'])\n",
    "    # suppl\n",
    "    train_active = pd.read_csv('input/train_active.csv', usecols=used_cols)\n",
    "    test_active = pd.read_csv('input/test_active.csv', usecols=used_cols)\n",
    "    train_periods = pd.read_csv('input/periods_train.csv', parse_dates=[\"date_from\", \"date_to\"])\n",
    "    test_periods = pd.read_csv('input/periods_test.csv', parse_dates=[\"date_from\", \"date_to\"])\n",
    "    #TODO new class#######################################\n",
    "    new_class = pd.read_csv(\"new_image_class_f600000.csv\")\n",
    "else:\n",
    "    train_df = pd.read_csv('input/train.csv', parse_dates = ['activation_date'])\n",
    "    train_df = shuffle(train_df, random_state=1234); train_df = train_df.iloc[:5000]\n",
    "    y = train_df[\"deal_probability\"]\n",
    "    test_df = pd.read_csv('input/test.csv', nrows=1000, parse_dates = ['activation_date'])\n",
    "    # suppl \n",
    "    train_active = pd.read_csv('input/train_active.csv', nrows=1000, usecols=used_cols)\n",
    "    test_active = pd.read_csv('input/test_active.csv', nrows=1000, usecols=used_cols)\n",
    "    train_periods = pd.read_csv('input/periods_train.csv', nrows=1000, parse_dates=[\"date_from\", \"date_to\"])\n",
    "    test_periods = pd.read_csv('input/periods_test.csv', nrows=1000, parse_dates=[\"date_from\", \"date_to\"])\n",
    "    #TODO new class#######################################\n",
    "    new_class = pd.read_csv(\"new_image_class_f600000.csv\")\n",
    "print(\"loading data done!\")\n",
    "\n",
    "# =============================================================================\n",
    "# Here Based on https://www.kaggle.com/bminixhofer/aggregated-features-lightgbm/code\n",
    "# =============================================================================\n",
    "all_samples = pd.concat([train_df,train_active,test_df,test_active]).reset_index(drop=True)\n",
    "all_samples.drop_duplicates([\"item_id\"], inplace=True)\n",
    "del train_active, test_active; gc.collect()\n",
    "\n",
    "all_periods = pd.concat([train_periods,test_periods])\n",
    "del train_periods, test_periods; gc.collect()\n",
    "\n",
    "all_periods[\"days_up\"] = (all_periods[\"date_to\"] - all_periods[\"date_from\"]).dt.days\n",
    "gp = all_periods.groupby([\"item_id\"])[[\"days_up\"]]\n",
    "\n",
    "gp_df = pd.DataFrame()\n",
    "gp_df[\"days_up_sum\"] = gp.sum()[\"days_up\"]\n",
    "gp_df[\"times_put_up\"] = gp.count()[\"days_up\"]\n",
    "gp_df.reset_index(inplace=True)\n",
    "gp_df.rename(index=str, columns={\"index\": \"item_id\"})\n",
    "\n",
    "all_periods.drop_duplicates([\"item_id\"], inplace=True)\n",
    "all_periods = all_periods.merge(gp_df, on=\"item_id\", how=\"left\")\n",
    "all_periods = all_periods.merge(all_samples, on=\"item_id\", how=\"left\")\n",
    "\n",
    "gp = all_periods.groupby([\"user_id\"])[[\"days_up_sum\", \"times_put_up\"]].mean().reset_index()\\\n",
    ".rename(index=str, columns={\"days_up_sum\": \"avg_days_up_user\",\n",
    "                            \"times_put_up\": \"avg_times_up_user\"})\n",
    "\n",
    "n_user_items = all_samples.groupby([\"user_id\"])[[\"item_id\"]].count().reset_index() \\\n",
    ".rename(index=str, columns={\"item_id\": \"n_user_items\"})\n",
    "gp = gp.merge(n_user_items, on=\"user_id\", how=\"outer\") #left\n",
    "\n",
    "del all_samples, all_periods, n_user_items\n",
    "gc.collect()\n",
    "\n",
    "train_df = train_df.merge(gp, on=\"user_id\", how=\"left\")\n",
    "test_df = test_df.merge(gp, on=\"user_id\", how=\"left\")\n",
    "\n",
    "agg_cols = list(gp.columns)[1:]\n",
    "\n",
    "del gp; gc.collect()\n",
    "\n",
    "for col in agg_cols:\n",
    "    train_df[col].fillna(-1, inplace=True)\n",
    "    test_df[col].fillna(-1, inplace=True)\n",
    "\n",
    "print(\"merging supplimentary data done!\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# done! go to the normal steps\n",
    "# =============================================================================\n",
    "def rmse(predictions, targets):\n",
    "    print(\"calculating RMSE ...\")\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def text_preprocessing(text):        \n",
    "    text = str(text)\n",
    "    text = text.lower() \n",
    "    # hash words\n",
    "    text = re.sub(r\"(\\\\u[0-9A-Fa-f]+)\",r\"\", text)\n",
    "    \n",
    "    text = re.sub(r\"===\",r\" \", text)\n",
    "    \n",
    "    # https://www.kaggle.com/demery/lightgbm-with-ridge-feature/code\n",
    "    text = \" \".join(map(str.strip, re.split('(\\d+)',text)))\n",
    "    regex = re.compile(u'[^[:alpha:]]')\n",
    "    text = regex.sub(\" \", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "@contextmanager\n",
    "def feature_engineering(df):\n",
    "    # All the feature engineering here  \n",
    "    \n",
    "    def Do_Text_Hash(df):\n",
    "        print(\"feature engineering -> hash text ...\")\n",
    "        df[\"text_feature\"] = df.apply(lambda row: \" \".join([str(row[\"param_1\"]),\n",
    "          str(row[\"param_2\"]), str(row[\"param_3\"])]),axis=1)\n",
    "    \n",
    "        df[\"text_feature_2\"] = df.apply(lambda row: \" \".join([str(row[\"param_2\"]), str(row[\"param_3\"])]),axis=1)        \n",
    "        df[\"title_description\"] = df.apply(lambda row: \" \".join([str(row[\"title\"]), str(row[\"description\"])]),axis=1)\n",
    "       \n",
    "        print(\"feature engineering -> preprocess text ...\")       \n",
    "        df[\"text_feature\"] = df[\"text_feature\"].apply(lambda x: text_preprocessing(x))\n",
    "        df[\"text_feature_2\"] = df[\"text_feature_2\"].apply(lambda x: text_preprocessing(x))\n",
    "        df[\"description\"] = df[\"description\"].apply(lambda x: text_preprocessing(x))\n",
    "        df[\"title\"] = df[\"title\"].apply(lambda x: text_preprocessing(x))\n",
    "        df[\"title_description\"] = df[\"title_description\"].apply(lambda x: text_preprocessing(x))\n",
    "                       \n",
    "    def Do_Datetime(df):\n",
    "        print(\"feature engineering -> date time ...\")\n",
    "        df[\"wday\"] = df[\"activation_date\"].dt.weekday\n",
    "#        df[\"week\"] = df[\"activation_date\"].dt.week\n",
    "#        df[\"dom\"] = df[\"activation_date\"].dt.day\n",
    "        \n",
    "    def Do_Label_Enc(df):\n",
    "        print(\"feature engineering -> lable encoding ...\")\n",
    "        lbl = LabelEncoder()\n",
    "        #TODO new class#######################################\n",
    "        cat_col = [\"user_id\", \"region\", \"city\", \"parent_category_name\",\n",
    "               \"category_name\", \"user_type\", \"image_top_1\",\n",
    "               \"param_1\", \"param_2\", \"param_3\",\"image\", \"new_class\"]\n",
    "        for col in cat_col:\n",
    "            df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "            gc.collect()\n",
    "    \n",
    "    import string\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])         \n",
    "    def Do_NA(df):\n",
    "        print(\"feature engineering -> fill na ...\")\n",
    "#        df[\"price\"] = np.log(df[\"price\"]+0.001).astype(\"float32\")\n",
    "#        df[\"price\"].fillna(-1,inplace=True)\n",
    "        df[\"image_top_1\"].fillna(-1,inplace=True)\n",
    "#        df[\"image_top_4\"].fillna(-1,inplace=True)\n",
    "        df[\"image\"].fillna(\"noinformation\",inplace=True)\n",
    "        df[\"param_1\"].fillna(\"nicapotato\",inplace=True)\n",
    "        df[\"param_2\"].fillna(\"nicapotato\",inplace=True)\n",
    "        df[\"param_3\"].fillna(\"nicapotato\",inplace=True)\n",
    "        df[\"title\"].fillna(\"nicapotato\",inplace=True)\n",
    "        df[\"description\"].fillna(\"nicapotato\",inplace=True)\n",
    "        \n",
    "    def Do_Count(df):  \n",
    "        print(\"feature engineering -> do count ...\")\n",
    "        # some count       \n",
    "        df[\"num_desc_punct\"] = df[\"description\"].apply(lambda x: count(x, set(string.punctuation)))\n",
    "        df[\"num_desc_capE\"] = df[\"description\"].apply(lambda x: count(x, \"[A-Z]\"))\n",
    "        df[\"num_desc_capP\"] = df[\"description\"].apply(lambda x: count(x, \"[А-Я]\"))\n",
    "        \n",
    "        df[\"num_title_punct\"] = df[\"title\"].apply(lambda x: count(x, set(string.punctuation)))\n",
    "        df[\"num_title_capE\"] = df[\"title\"].apply(lambda x: count(x, \"[A-Z]\"))\n",
    "        df[\"num_title_capP\"] = df[\"title\"].apply(lambda x: count(x, \"[А-Я]\"))               \n",
    "        # good, used, bad ... count\n",
    "        df[\"is_in_desc_хорошо\"] = df[\"description\"].str.contains(\"хорошо\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_Плохо\"] = df[\"description\"].str.contains(\"Плохо\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_новый\"] = df[\"description\"].str.contains(\"новый\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_старый\"] = df[\"description\"].str.contains(\"старый\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_используемый\"] = df[\"description\"].str.contains(\"используемый\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_есплатная_доставка\"] = df[\"description\"].str.contains(\"есплатная доставка\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_есплатный_возврат\"] = df[\"description\"].str.contains(\"есплатный возврат\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_идеально\"] = df[\"description\"].str.contains(\"идеально\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_подержанный\"] = df[\"description\"].str.contains(\"подержанный\").map({True:1, False:0})\n",
    "        df[\"is_in_desc_пСниженные_цены\"] = df[\"description\"].str.contains(\"Сниженные цены\").map({True:1, False:0})\n",
    "        \n",
    "                              \n",
    "    def Do_Drop(df):\n",
    "        df.drop([\"activation_date\", \"item_id\"], axis=1, inplace=True)\n",
    "        \n",
    "    def Do_Stat_Text(df):\n",
    "        print(\"feature engineering -> statistics in text ...\")\n",
    "        textfeats = [\"text_feature\",\"text_feature_2\",\"description\", \"title\"]\n",
    "        for col in textfeats:\n",
    "            df[col + \"_num_chars\"] = df[col].apply(len) \n",
    "            df[col + \"_num_words\"] = df[col].apply(lambda comment: len(comment.split()))\n",
    "            df[col + \"_num_unique_words\"] = df[col].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "            df[col + \"_words_vs_unique\"] = df[col+\"_num_unique_words\"] / df[col+\"_num_words\"] * 100\n",
    "            gc.collect()\n",
    "                      \n",
    "    # choose which functions to run\n",
    "    Do_NA(df)\n",
    "    Do_Text_Hash(df)\n",
    "    Do_Label_Enc(df)\n",
    "    Do_Count(df)\n",
    "    Do_Datetime(df)   \n",
    "    Do_Stat_Text(df)       \n",
    "    Do_Drop(df)    \n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def data_vectorize(df):\n",
    "    russian_stop = set(stopwords.words(\"russian\"))\n",
    "    tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": \"word\",\n",
    "    \"token_pattern\": r\"\\w{1,}\",\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": \"l2\",\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "    }\n",
    "    def get_col(col_name): return lambda x: x[col_name]\n",
    "    vectorizer = FeatureUnion([\n",
    "        (\"description\", TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=18000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col(\"description\"))\n",
    "         ),\n",
    "        (\"title_description\", TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=18000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col(\"title_description\"))\n",
    "         ),\n",
    "        (\"text_feature\", CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            preprocessor=get_col(\"text_feature\"))\n",
    "         ),\n",
    "        (\"title\", TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col(\"title\"))\n",
    "         ),\n",
    "    ])\n",
    "    vectorizer.fit(df.to_dict(\"records\"))\n",
    "    ready_full_df = vectorizer.transform(df.to_dict(\"records\"))    \n",
    "    tfvocab = vectorizer.get_feature_names()    \n",
    "    df.drop([\"text_feature\", \"text_feature_2\", \"description\",\"title\", \"title_description\"], axis=1, inplace=True)\n",
    "    df.fillna(-1, inplace=True)     \n",
    "    return df, ready_full_df, tfvocab\n",
    "# =============================================================================\n",
    "# Ridge feature https://www.kaggle.com/demery/lightgbm-with-ridge-feature/code\n",
    "# =============================================================================\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool = True):\n",
    "        if(seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "NFOLDS = 10#5\n",
    "SEED = 42\n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "            \n",
    "    oof_train = np.zeros((len_train,))\n",
    "    oof_test = np.zeros((len_test,))\n",
    "    oof_test_skf = np.empty((NFOLDS, len_test))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('Ridege oof Fold {}'.format(i))\n",
    "        x_tr = x_train[train_index]       \n",
    "        y = np.array(y)\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]      \n",
    "        clf.train(x_tr, y_tr)       \n",
    "        oof_train[test_index] = clf.predict(x_te)        \n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "full_df = pd.concat([train_df, test_df])\n",
    "#TODO new class#######################################\n",
    "full_df = pd.merge(full_df, new_class, how='left', on=['image_top_1'])\n",
    "full_df[\"new_class\"].fillna(\"beijing\",inplace=True)\n",
    "#print(full_df.head())\n",
    "sub_item_id = test_df[\"item_id\"]\n",
    "len_train = len(train_df)\n",
    "len_test = len(test_df)\n",
    "\n",
    "kf = KFold(len_train, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "# =============================================================================\n",
    "# handle price\n",
    "# =============================================================================\n",
    "def feature_Eng_On_Price_SEQ(df):\n",
    "    print('feature engineering -> on price and SEQ ...')        \n",
    "    df[\"price\"] = np.log(df[\"price\"]+0.001).astype(\"float32\")\n",
    "    df[\"price\"].fillna(-1,inplace=True)     \n",
    "    df[\"price+\"] = np.round(df[\"price\"]*4.8).astype(int)   \n",
    "    df[\"item_seq_number+\"] = np.round(df[\"item_seq_number\"]/100).astype(int) \n",
    "    return df\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    full_df.iloc[:len_train], test_size=0.1, random_state=42) #23    \n",
    "def feature_Eng_On_Deal_Prob(df, df_train):\n",
    "    print('feature engineering -> on price deal prob +...')\n",
    "    df2 = df    \n",
    "    tmp = df_train.groupby([\"price+\"], as_index=False)['deal_probability'].median().rename(columns={'deal_probability':'median_deal_probability_price+'})     \n",
    "    df = pd.merge(df, tmp, how='left', on=[\"price+\"])\n",
    "    df2['median_deal_probability_price+'] = df['median_deal_probability_price+']  \n",
    "    del tmp; gc.collect()\n",
    "    \n",
    "    tmp = df_train.groupby([\"item_seq_number+\"], as_index=False)['deal_probability'].median().rename(columns={'deal_probability':'median_deal_probability_item_seq_number+'})     \n",
    "    df = pd.merge(df, tmp, how='left', on=[\"item_seq_number+\"])\n",
    "    df2['median_deal_probability_item_seq_number+'] = df['median_deal_probability_item_seq_number+']\n",
    "       \n",
    "    df2.fillna(-1, inplace=True)    \n",
    "    del tmp; gc.collect()\n",
    "    return df2\n",
    "\n",
    "del full_df['deal_probability']; gc.collect()\n",
    "\n",
    "# =============================================================================\n",
    "# use additianl image data\n",
    "# =============================================================================\n",
    "feature_engineering(full_df)\n",
    "\n",
    "feature_Eng_On_Price_SEQ(full_df)\n",
    "feature_Eng_On_Price_SEQ(train_df)\n",
    "feature_Eng_On_Deal_Prob(full_df, train_df)\n",
    "\n",
    "del train_df, test_df; gc.collect()\n",
    "full_df, ready_full_df, tfvocab = data_vectorize(full_df)\n",
    "\n",
    "#'alpha':20.0\n",
    "ridge_params = {'alpha':20.0, 'fit_intercept':True, 'normalize':False, 'copy_X':True,\n",
    "                'max_iter':None, 'tol':0.001, 'solver':'auto', 'random_state':SEED}\n",
    "ridge = SklearnWrapper(clf=Ridge, seed = SEED, params = ridge_params)\n",
    "ready_df = ready_full_df\n",
    "\n",
    "print('ridge 1 oof ...')\n",
    "ridge_oof_train, ridge_oof_test = get_oof(ridge, np.array(full_df)[:len_train], y, np.array(full_df)[len_train:])\n",
    "ridge_preds = np.concatenate([ridge_oof_train, ridge_oof_test])\n",
    "full_df['ridge_preds_1'] = ridge_preds\n",
    "full_df['ridge_preds_1'].clip(0.0, 1.0, inplace=True)\n",
    "\n",
    "print('ridge 2 oof ...')\n",
    "ridge_oof_train, ridge_oof_test = get_oof(ridge, ready_df[:len_train], y, ready_df[len_train:])\n",
    "ridge_preds = np.concatenate([ridge_oof_train, ridge_oof_test])\n",
    "full_df['ridge_preds_2'] = ridge_preds\n",
    "full_df['ridge_preds_2'].clip(0.0, 1.0, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Modeling Stage ...\")\n",
    "# Combine Dense Features with Sparse Text Bag of Words Features\n",
    "X = hstack([csr_matrix(full_df.iloc[:len_train]), ready_full_df[:len_train]]) # Sparse Matrix\n",
    "test = hstack([csr_matrix(full_df.iloc[len_train:]), ready_full_df[len_train:]]) # Sparse Matrix\n",
    "tfvocab = full_df.columns.tolist() + tfvocab\n",
    "\n",
    "\n",
    "for shape in [X,test]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "#TODO new class#######################################\n",
    "cat_col = [\n",
    "           \"user_id\",\n",
    "           \"region\", \n",
    "           \"city\", \n",
    "           \"parent_category_name\",\n",
    "           \"category_name\", \n",
    "           \"user_type\", \n",
    "           \"image_top_1\",\n",
    "           \"param_1\", \n",
    "           \"param_2\", \n",
    "           \"param_3\",\n",
    "           \"price+\",\n",
    "           \"item_seq_number+\",\n",
    "           \"new_class\"\n",
    "           ]\n",
    "\n",
    "rmse_sume = 0.\n",
    "\n",
    "for numIter in range(0, 1):\n",
    "      \n",
    "      X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42) #23\n",
    "      \n",
    "#      X_train, X_valid = X.tocsr()[train_index], X.tocsr()[test_index]\n",
    "#      y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "     \n",
    "      lgbm_params =  {\n",
    "              \"tree_method\": \"feature\",    \n",
    "              \"num_threads\": 3,\n",
    "              \"task\": \"train\",\n",
    "              \"boosting_type\": \"gbdt\",\n",
    "              \"objective\": \"regression\",\n",
    "              \"metric\": \"rmse\",\n",
    "      #        \"max_depth\": 15,\n",
    "              \"num_leaves\": 280, # 35\n",
    "              \"feature_fraction\": 0.6,\n",
    "              \"bagging_fraction\": 0.6,\n",
    "              \"learning_rate\": 0.019,\n",
    "              \"verbose\": -1,\n",
    "              'lambda_l1':1,\n",
    "              'lambda_l2':1,\n",
    "              }\n",
    "      \n",
    "      lgtrain = lgb.Dataset(X_train, y_train,\n",
    "                      feature_name=tfvocab,\n",
    "                      categorical_feature = cat_col)\n",
    "      lgvalid = lgb.Dataset(X_valid, y_valid,\n",
    "                      feature_name=tfvocab,\n",
    "                      categorical_feature = cat_col)\n",
    "      lgb_clf = lgb.train(\n",
    "              lgbm_params,\n",
    "              lgtrain,\n",
    "              num_boost_round=32000,\n",
    "              valid_sets=[lgtrain, lgvalid],\n",
    "              valid_names=[\"train\",\"valid\"],\n",
    "              early_stopping_rounds=200,\n",
    "              verbose_eval=100, #200\n",
    "              )\n",
    "      \n",
    "      print(\"save model ...\")\n",
    "      joblib.dump(lgb_clf, \"lgb_{}.pkl\".format(numIter))\n",
    "      ## load model\n",
    "      #lgb_clf = joblib.load(\"lgb.pkl\")\n",
    "      \n",
    "      print(\"Model Evaluation Stage\")\n",
    "      print( \"RMSE:\", rmse(y_valid, lgb_clf.predict(X_valid, num_iteration=lgb_clf.best_iteration)) )\n",
    "      lgpred = lgb_clf.predict(test, num_iteration=lgb_clf.best_iteration)\n",
    "      \n",
    "      lgsub = pd.DataFrame(lgpred,columns=[\"deal_probability\"],index=sub_item_id)\n",
    "      lgsub[\"deal_probability\"].clip(0.0, 1.0, inplace=True) # Between 0 and 1\n",
    "      lgsub.to_csv(\"ml_lgb_sub_{}.csv\".format(numIter),index=True,header=True)\n",
    "\n",
    "      rmse_sume += rmse(y_valid, lgb_clf.predict(X_valid, num_iteration=lgb_clf.best_iteration))\n",
    "      \n",
    "      numIter += 1\n",
    "      \n",
    "      del X_train, X_valid, y_train, y_valid, lgtrain, lgvalid\n",
    "      gc.collect()\n",
    "\n",
    "print(\"mean rmse is:\", rmse_sume/5)\n",
    "      \n",
    "print(\"Features importance...\")\n",
    "bst = lgb_clf\n",
    "gain = bst.feature_importance(\"gain\")\n",
    "ft = pd.DataFrame({\"feature\":bst.feature_name(), \"split\":bst.feature_importance(\"split\"), \"gain\":100 * gain / gain.sum()}).sort_values(\"gain\", ascending=False)\n",
    "print(ft.head(50))\n",
    "\n",
    "plt.figure()\n",
    "ft[[\"feature\",\"gain\"]].head(50).plot(kind=\"barh\", x=\"feature\", y=\"gain\", legend=False, figsize=(10, 20))\n",
    "plt.gcf().savefig(\"features_importance.png\")\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "mean rmse is: 0.21697176669518864\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
